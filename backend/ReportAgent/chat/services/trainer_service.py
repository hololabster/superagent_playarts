import json
from .background_remover import UniversalBackgroundRemover
import os
import random
import uuid
import subprocess
import time
import math
import threading
import logging
import re
from PIL import Image, ImageOps
import cv2
import numpy as np
from django.conf import settings
from .topic_extractor import TopicExtractor
from ..models import AgentModel, TrainingJob  
logger = logging.getLogger(__name__)
class TrainerService:
    def __init__(self):
        self.job_queue = []
        self.running_jobs = {}
        self.max_concurrent_jobs = 3
        self.logs = {}
        self.last_read_index = {}  # 각 task_id별 마지막으로 읽은 로그 인덱스 추적
        self.available_gpus = [4]
        self.logs = {}

        t = threading.Thread(target=self._worker_loop, daemon=True)
        t.start()

        # 수정된 TopicExtractor
        self.topic_extractor = TopicExtractor(
            model_path="/home/ubuntu/additional_storage/ai-toolkit/superagent_playarts/ReportAgent/ai_models",
            device=None
        )
        # Initialize background remover
        self.background_remover = UniversalBackgroundRemover(
            sam_checkpoint="/home/ubuntu/additional_storage/ai-toolkit/superagent_playarts/ReportAgent/ai_models/sam_vit_h_4b8939.pth",
            model_type="vit_h",
            device="cuda:4"  # Using GPU 4 as specified in available_gpus
        )
        
        t = threading.Thread(target=self._worker_loop, daemon=True)
        t.start()
        
        self.topic_extractor = TopicExtractor(
            model_path="/home/ubuntu/additional_storage/ai-toolkit/superagent_playarts/ReportAgent/ai_models",
            device=None
        )


    def _store_agent_mapping(self, agent_key: str, model_name: str):
        """Store mapping of agent key to model name for dynamic API access"""
        # Create mapping directory if it doesn't exist
        mapping_dir = "/home/ubuntu/additional_storage/ai-toolkit/agent_mappings"
        os.makedirs(mapping_dir, exist_ok=True)
        
        # Create or update mapping file
        mapping_file = os.path.join(mapping_dir, "agent_mappings.json")
        
        mappings = {}
        if os.path.exists(mapping_file):
            try:
                with open(mapping_file, 'r') as f:
                    mappings = json.load(f)
            except Exception as e:
                logger.error(f"Error reading agent mappings file: {e}")
                # If file is corrupted, start fresh
                mappings = {}
        
        mappings[agent_key] = model_name
        
        with open(mapping_file, 'w') as f:
            json.dump(mappings, f, indent=2)
        
        logger.info(f"Stored agent mapping: {agent_key} -> {model_name}")

    def start_lora_training(self, character_name: str, source_image_path: str) -> str:
        """
        Generate a unique agent key for new character and start training process
        
        Args:
            character_name: Name of the character to train
            source_image_path: Path to the source image
            
        Returns:
            task_id: Unique identifier for the training task
        """
        # 절대 경로 사용 (chat은 앱 이름에 맞게 조정)
        from django.db import transaction
        
        sanitized_character = character_name.replace(" ", "")
        task_id = str(uuid.uuid4())[:8]
        
        # Create a new AgentModel entry with a unique key
        agent = AgentModel.objects.create(
            model_name=sanitized_character,
        )
        
        # The UUID is auto-generated by the model
        agent_key = str(agent.agent_key)
        logger.info(f"Created new agent with key {agent_key} for model {sanitized_character}")
        
        dataset_folder = f"/mnt/striped_nvme/ai-toolkit/{sanitized_character}_dataset"
        os.makedirs(dataset_folder, exist_ok=True)
        
        try:
            cutout_path = os.path.join(dataset_folder, "cutout.png")
            self._remove_background(source_image_path, cutout_path)
            
            # 합성 + 해석 (파일명: short_topic, .txt: full_caption)
            self._composite_and_interpret(cutout_path, dataset_folder, sanitized_character)
            
            config_path = f"/mnt/striped_nvme/ai-toolkit/config/{sanitized_character}_config.yaml"
            job_name = f"{sanitized_character}_flux_lora_v1"
            
            config_path = self._generate_training_config(
                config_path=config_path,
                job_name=job_name,
                dataset_folder=dataset_folder,
                base_model="black-forest-labs/FLUX.1-schnell",
                gpu_id=None
            )
            
            job_info = {
                "task_id": task_id,
                "character_name": sanitized_character,
                "agent_key": agent_key,  # Store the agent key
                "config_path": config_path,
                "gpu_id": None,
                "status": "queued",
                "progress": 0
            }
            
            self.job_queue.append((task_id, job_info))
            
            # character_name으로 TrainingJob을 조회
            try:
                with transaction.atomic():
                    training_job = TrainingJob.objects.get(character_name=sanitized_character)
                    training_job.task_id = task_id
                    training_job.agent = agent
                    training_job.save()
            except TrainingJob.DoesNotExist:
                logger.warning(f"No TrainingJob found for character '{sanitized_character}'. Creating new one.")
                # TrainingJob을 찾을 수 없으면 새로 생성
                training_job = TrainingJob.objects.create(
                    character_name=sanitized_character,
                    task_id=task_id,
                    agent=agent,
                    status='queued',
                    dataset_path=dataset_folder,
                    original_image=source_image_path,
                    progress=0
                )
            except Exception as e:
                logger.error(f"Error updating/creating TrainingJob: {e}", exc_info=True)
                
            return task_id
            
        except Exception as e:
            logger.error(f"Error in start_lora_training: {e}", exc_info=True)
            # Delete the agent if training setup fails
            agent.delete()
            raise

    def _worker_loop(self):
        while True:
            if len(self.running_jobs) < self.max_concurrent_jobs and self.job_queue:
                if self.available_gpus:
                    gpu_id = self.available_gpus.pop(0)
                else:
                    time.sleep(1)
                    continue
                task_id, job_info = self.job_queue.pop(0)
                job_info["gpu_id"] = gpu_id
                self.running_jobs[task_id] = job_info

                t = threading.Thread(target=self._run_training_job, args=(task_id, job_info), daemon=True)
                t.start()
            else:
                time.sleep(1)

    def _run_training_job(self, task_id: str, job_info: dict):
        try:
            character_name = job_info["character_name"] 
            config_path = job_info["config_path"]
            gpu_id = job_info["gpu_id"]
            agent_key = job_info.get("agent_key", "")  # Get agent key
            
            conda_python = "/mnt/striped_nvme/ai-toolkit/venv/bin/python"
            run_script = "/mnt/striped_nvme/ai-toolkit/run.py"
            
            if task_id not in self.logs:
                self.logs[task_id] = []
                
            # 초기 상태 설정 
            job_info["status"] = "initializing"
            job_info["progress"] = 0
            self.logs[task_id].append(f"Initializing training on GPU {gpu_id}.\n")
            
            cmd = [conda_python, run_script, config_path]
            env = os.environ.copy()
            env["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
            logger.info(f"[{task_id}] Running command: {' '.join(cmd)}")
            
            # Update DB status
            from ..models import TrainingJob
            try:
                job = TrainingJob.objects.get(task_id=task_id)
                job.status = 'training'
                job.save()
            except TrainingJob.DoesNotExist:
                logger.warning(f"[{task_id}] Training job not found in database")
            
            # 표준 출력과 에러를 모두 캡처
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,  # stderr를 stdout으로 리다이렉트
                env=env,
                universal_newlines=True,
                bufsize=1
            )
            
            full_output = []
            last_step_detected = False  # 마지막 스텝 감지 (ex: 99/100)
            unloading_lora_detected = False  # "Unloading assistant lora" 메시지 감지
            optimizer_saved = False  # optimizer.pt 저장 감지
            training_completed = False
            total_steps = 1000  # 기본 스텝 수
            current_step = 0
            
            for line in process.stdout:
                line = line.rstrip()
                full_output.append(line)
                self.logs[task_id].append(f"{line}\n")
                logger.info(f"[{task_id}][GPU:{gpu_id}] {line}")
                
                # 진행률 감지
                if "_flux_lora_v1:" in line:
                    progress_match = re.search(r"(\d+)/(\d+)\s+\[", line)
                    if progress_match:
                        current_step = int(progress_match.group(1))
                        total_steps = int(progress_match.group(2))
                        
                        progress_percent = (current_step / total_steps) * 100
                        job_info["progress"] = progress_percent
                        job_info["status"] = "training"
                        
                        # Update progress in DB
                        try:
                            job = TrainingJob.objects.get(task_id=task_id)
                            job.progress = progress_percent
                            job.save()
                        except Exception as e:
                            logger.error(f"[{task_id}] Error updating progress: {e}")
                        
                        # 마지막 스텝 감지 (ex: 99/100)
                        if current_step == total_steps - 1:
                            last_step_detected = True
                            logger.info(f"[{task_id}] Final training step detected: {current_step}/{total_steps}")
                        
                        # 마지막 스텝 감지 (ex: 100/100)
                        if current_step == total_steps:
                            last_step_detected = True
                            logger.info(f"[{task_id}] Final training step detected: {current_step}/{total_steps}")
                
                # "Unloading assistant lora" 메시지 감지
                if "Unloading assistant lora" in line:
                    unloading_lora_detected = True
                    logger.info(f"[{task_id}] Detected 'Unloading assistant lora'")
                
                # optimizer.pt 저장 감지
                if "Saved to" in line and "optimizer.pt" in line:
                    optimizer_saved = True
                    logger.info(f"[{task_id}] Detected optimizer.pt save")
                
                # 학습 완료 조건: (마지막 스텝 + optimizer.pt 저장) 또는 (Unloading lora + optimizer.pt 저장)
                if ((last_step_detected or unloading_lora_detected) and optimizer_saved) and not training_completed:
                    training_completed = True
                    job_info["status"] = "completed"
                    job_info["progress"] = 100
                    
                    logger.info(f"[{task_id}] Training completion confirmed, model is ready for inference.")
                    
                    try:
                        # Update DB status
                        job = TrainingJob.objects.get(task_id=task_id)
                        job.status = 'completed'
                        job.progress = 100
                        job.save()
                        
                        # Force model manager to reload available models
                        from ..services.model_manager import get_model_manager
                        model_manager = get_model_manager()
                        model_manager.reload_models()
                        
                        # 에이전트 매핑 저장
                        self._store_agent_mapping(agent_key, character_name)
                        
                        # Generate and log the inference URL
                        if agent_key:
                            inference_url = f"https://api-ai-agent.playarts.ai/agent/{agent_key}/inference"
                            success_msg = f"Training completed! Your character is now accessible via the API at: {inference_url}"
                            api_usage_msg = f"To generate images, send a POST request with: {{\"prompt\": \"your prompt\", \"aspect_ratio\": \"square\", \"seed\": 42}}"
                            
                            # 로그에 추가 (더 눈에 띄게)
                            self.logs[task_id].append(f"\n{'-'*50}\n")
                            self.logs[task_id].append(success_msg + "\n")
                            self.logs[task_id].append(api_usage_msg + "\n")
                            self.logs[task_id].append(f"{'-'*50}\n")
                            
                            logger.info(f"[{task_id}] {success_msg}")
                            
                            # 에이전트 서버 실행 확인
                            try:
                                self._ensure_agent_server_running(7)  # GPU 7 사용
                                self.logs[task_id].append(f"API server is running for inference on GPU 7.\n")
                            except Exception as server_error:
                                logger.error(f"[{task_id}] Error ensuring agent server: {server_error}")
                                self.logs[task_id].append(f"Warning: Could not verify API server: {str(server_error)}\n")
                    except Exception as e:
                        error_msg = f"Failed to update completed status: {str(e)}"
                        logger.error(f"[{task_id}] {error_msg}")
                        self.logs[task_id].append(f"Error: {error_msg}\n")
                            
            # 프로세스 종료 대기
            process.wait()
            
            # Handle process completion
            if process.returncode == 0:
                # 이미 트레이닝 완료로 표시되어 있으면 추가 조치 필요 없음
                if training_completed:
                    logger.info(f"[{task_id}] Process completed successfully with training completion detected")
                    return "completed"
                else:
                    # 프로세스는 정상 종료되었지만 명확한 트레이닝 완료 신호를 감지하지 못한 경우
                    # 진행률이 높다면(>90%) 완료로 처리
                    progress = job_info.get("progress", 0)
                    if progress > 90 or optimizer_saved:
                        logger.warning(f"[{task_id}] Process completed with return code 0. No explicit completion detected, but progress was {progress}%. Marking as completed.")
                        job_info["status"] = "completed"
                        job_info["progress"] = 100
                        
                        # Update DB
                        try:
                            job = TrainingJob.objects.get(task_id=task_id)
                            job.status = 'completed'
                            job.progress = 100
                            job.save()
                            
                            # Generate and log the inference URL (if it wasn't done earlier)
                            if agent_key and not training_completed:
                                inference_url = f"https://api-ai-agent.playarts.ai/agent/{agent_key}/inference"
                                success_msg = f"Training likely completed! Your character should be accessible via the API at: {inference_url}"
                                api_usage_msg = f"To generate images, send a POST request with: {{\"prompt\": \"your prompt\", \"aspect_ratio\": \"square\", \"seed\": 42}}"
                                
                                self.logs[task_id].append(f"\n{'-'*50}\n")
                                self.logs[task_id].append(success_msg + "\n")
                                self.logs[task_id].append(api_usage_msg + "\n")
                                self.logs[task_id].append(f"{'-'*50}\n")
                                
                                logger.info(f"[{task_id}] {success_msg}")
                                
                                # 에이전트 매핑 저장
                                self._store_agent_mapping(agent_key, character_name)
                        except Exception as e:
                            logger.error(f"[{task_id}] Error updating job status: {e}")
                        
                        from ..services.model_manager import get_model_manager
                        model_manager = get_model_manager()
                        model_manager.reload_models()
                        
                        # 에이전트 서버 실행 확인
                        try:
                            self._ensure_agent_server_running(7)  # GPU 7 사용
                        except Exception as server_error:
                            logger.error(f"[{task_id}] Error ensuring agent server: {server_error}")
                        
                        return "completed"
                    else:
                        # 진행률이 낮은 상태에서 종료된 경우 - 실패로 처리
                        logger.warning(f"[{task_id}] Process completed but progress was only {progress}%. Marking as failed.")
                        job_info["status"] = "failed"
                        
                        # Update DB
                        try:
                            job = TrainingJob.objects.get(task_id=task_id)
                            job.status = 'failed'
                            job.save()
                        except Exception as e:
                            logger.error(f"[{task_id}] Error updating job status: {e}")
                        
                        return "failed"
            else:
                # Process failed
                job_info["status"] = "failed"
                error_msg = f"Process failed with return code {process.returncode}"
                logger.error(f"[{task_id}] {error_msg}")
                self.logs[task_id].append(error_msg + "\n")
                
                # Update DB
                try:
                    job = TrainingJob.objects.get(task_id=task_id)
                    job.status = 'failed'
                    job.save()
                except Exception as e:
                    logger.error(f"[{task_id}] Error updating job status: {e}")
                    
                return "failed"
        except Exception as e:
            logger.error(f"[{task_id}] Error in training job: {str(e)}", exc_info=True)
            job_info["status"] = "failed"
            
            # Update DB
            try:
                from ..models import TrainingJob
                job = TrainingJob.objects.get(task_id=task_id)
                job.status = 'failed'
                job.save()
            except Exception as db_error:
                logger.error(f"[{task_id}] Error updating job status: {db_error}")
                
            return "failed"
        finally:
            if gpu_id is not None and gpu_id not in self.available_gpus:
                self.available_gpus.append(gpu_id)

    def _ensure_agent_server_running(self, gpu_id):
        """Check if the agent server is running and start it if needed"""
        try:
            # Path to the superagent script
            script_path = "/home/ubuntu/additional_storage/ai-toolkit/output/scripts/generate_image_for_the_superagent.py"
            
            # Check if the script exists
            if not os.path.exists(script_path):
                logger.error(f"Agent server script not found at {script_path}")
                # Create the directory if it doesn't exist
                os.makedirs(os.path.dirname(script_path), exist_ok=True)
                
                # Copy our script to the location
                import shutil
                source_script = "/home/ubuntu/additional_storage/ai-toolkit/generate_image_for_the_superagent.py"
                if os.path.exists(source_script):
                    shutil.copy(source_script, script_path)
                    logger.info(f"Copied agent server script from {source_script} to {script_path}")
                else:
                    raise FileNotFoundError(f"Source script not found at {source_script}")
            
            # Check if already running (simple check by port)
            import socket
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            try:
                s.connect(("localhost", 5100))
                s.close()
                logger.info(f"Agent server already running")
                return  # Server is already running
            except:
                logger.info(f"Agent server not running, starting...")
            
            # Start the server - Always use GPU 7 for inference
            gpuIdToUse = "7"  # Always use GPU 7 for inference regardless of DEBUG setting
            command = f"source /home/ubuntu/additional_storage/ai-toolkit/venv/bin/activate && python {script_path} --gpu_id {gpuIdToUse} --port 5100"
            
            # Use nohup to keep the process running even after our script exits
            full_command = f"nohup bash -c '{command}' > /home/ubuntu/additional_storage/ai-toolkit/output/agent_server.log 2>&1 &"
            
            # Execute the command
            subprocess.Popen(full_command, shell=True)
            
            logger.info(f"Started agent server on GPU {gpuIdToUse}")
            
            # Wait a bit for the server to start
            import time
            time.sleep(5)
            
        except Exception as e:
            logger.error(f"Error ensuring agent server is running: {e}")
            raise

    def _remove_background(self, source_image_path: str, out_path: str):
        """
        Remove background using SAM-based universal background remover
        """
        try:
            # Load image for style detection
            img = Image.open(source_image_path)
            img_array = np.array(img)
            
            # Calculate image statistics for style detection
            edge_density = cv2.Canny(img_array, 100, 200).mean()
            color_variance = img_array.std(axis=(0,1)).mean()
            
            # Adjust effect preservation based on image style
            if edge_density > 50 and color_variance < 60:  # Likely illustration/anime
                effect_preservation = 0.7
            else:  # Likely photo
                effect_preservation = 0.3
            
            # Remove background with appropriate effect preservation
            self.background_remover.remove_background(
                source_image_path,
                out_path,
                effect_preservation=effect_preservation
            )
            
            logger.info(f"Successfully removed background from {source_image_path} with effect_preservation={effect_preservation}")
            
        except Exception as e:
            logger.error(f"Error in background removal: {str(e)}")
            raise

    def _composite_and_interpret(self, cutout_path: str, dataset_folder: str, character_name: str):
        """
        Enhanced compositing function that ensures character emphasis:
        1. Maintains minimum character size relative to background
        2. Enhances character edges
        3. Ensures character takes up significant portion of the image
        """
        backgrounds_dir = "/home/ubuntu/additional_storage/ai-toolkit/superagent_playarts/ReportAgent/wallet_chat/static/backgrounds"
        bg_files = sorted([
            f for f in os.listdir(backgrounds_dir)
            if f.lower().endswith(('.png', '.jpg', '.jpeg'))
        ])
        if not bg_files:
            raise RuntimeError("No background images found in backgrounds directory")

        num_backgrounds = len(bg_files)
        num_images_needed = 50
        variations_per_bg = max(2, num_images_needed // num_backgrounds)

        # Load and enhance character cutout
        cutout_img = Image.open(cutout_path).convert("RGBA")
        
        # Enhance edges of the character
        from PIL import ImageEnhance, ImageFilter
        
        # Create alpha mask
        alpha = cutout_img.split()[3]
        
        # Enhance edges in alpha channel
        enhanced_alpha = alpha.filter(ImageFilter.EDGE_ENHANCE_MORE)
        enhanced_alpha = ImageEnhance.Contrast(enhanced_alpha).enhance(1.2)
        
        # Merge back enhanced alpha
        r, g, b, _ = cutout_img.split()
        cutout_img = Image.merge('RGBA', (r, g, b, enhanced_alpha))
        
        c_w, c_h = cutout_img.width, cutout_img.height

        # Calculate minimum size ratio (character should take up at least 15% of the image area)
        MIN_AREA_RATIO = 0.15
        
        composite_count = 0
        bg_cycle = 0

        while composite_count < num_images_needed:
            bg_index = bg_cycle % num_backgrounds
            bg_file = bg_files[bg_index]
            bg_path = os.path.join(backgrounds_dir, bg_file)

            try:
                bg_img = Image.open(bg_path).convert("RGBA")
            except Exception as e:
                logger.error(f"Error loading background {bg_file}: {str(e)}")
                bg_cycle += 1
                continue

            bg_w, bg_h = bg_img.width, bg_img.height
            bg_area = bg_w * bg_h
            
            remaining = num_images_needed - composite_count
            variations = min(variations_per_bg, remaining)

            for _ in range(variations):
                # Calculate scaling to ensure minimum area coverage
                if c_w == 0 or c_h == 0:
                    scale_factor = 0.5
                else:
                    # Calculate minimum scale needed for area ratio
                    min_scale_area = math.sqrt((bg_area * MIN_AREA_RATIO) / (c_w * c_h))
                    
                    # Calculate maximum scale (80% of background)
                    max_scale_w = (bg_w * 0.8) / c_w
                    max_scale_h = (bg_h * 0.8) / c_h
                    max_scale = min(max_scale_w, max_scale_h)
                    
                    # Ensure scale is between min_scale_area and max_scale
                    min_scale = max(0.4, min_scale_area)  # At least 40% of original size
                    max_scale = min(0.8, max_scale)       # At most 80% of background
                    
                    if max_scale < min_scale:
                        scale_factor = min_scale
                    else:
                        # Bias towards larger sizes (using power distribution)
                        random_power = random.uniform(1.5, 2.0)  # Bias towards larger values
                        scale_factor = min_scale + (max_scale - min_scale) * (random.random() ** (1/random_power))

                new_w = int(c_w * scale_factor)
                new_h = int(c_h * scale_factor)
                
                # High-quality resize with edge preservation
                resized_cutout = cutout_img.resize((new_w, new_h), Image.LANCZOS)
                
                # Apply additional edge enhancement after resize
                r, g, b, a = resized_cutout.split()
                a = a.filter(ImageFilter.EDGE_ENHANCE)
                resized_cutout = Image.merge('RGBA', (r, g, b, a))

                # Position character more prominently (avoid edges)
                margin = int(min(bg_w, bg_h) * 0.1)  # 10% margin
                max_x = max(0, bg_w - new_w - 2*margin)
                max_y = max(0, bg_h - new_h - 2*margin)
                x_offset = margin + random.randint(0, max_x) if max_x > 0 else margin
                y_offset = margin + random.randint(0, max_y) if max_y > 0 else margin

                # Moderate rotation (-20~+20 instead of -30~+30)
                angle = random.uniform(-20, 20)
                transformed_cutout = resized_cutout.rotate(angle, expand=True, resample=Image.BICUBIC)
                
                # 50% chance of horizontal flip
                if random.random() < 0.5:
                    transformed_cutout = ImageOps.mirror(transformed_cutout)

                # Composite with slight character emphasis
                composite = bg_img.copy()
                
                # Slightly blur background to emphasize character
                composite = composite.filter(ImageFilter.GaussianBlur(radius=0.5))
                
                # Composite character
                composite.alpha_composite(transformed_cutout, dest=(x_offset, y_offset))

                # Save with enhanced quality
                temp_filename = f"{character_name}_temp_{composite_count:05d}.png"
                temp_path = os.path.join(dataset_folder, temp_filename)
                composite.convert("RGB").save(temp_path, format="PNG", quality=95)

                # Extract caption and save
                full_caption, short_topic = self.topic_extractor.extract_caption_and_topic(temp_path)
                short_topic = short_topic[:30]
                short_topic = re.sub(r'[^a-zA-Z0-9_]', '_', short_topic).strip('_')
                if not short_topic:
                    short_topic = "noTopic"

                final_filename = f"{character_name}_{short_topic}_{composite_count:05d}.png"
                final_path = os.path.join(dataset_folder, final_filename)
                os.rename(temp_path, final_path)

                caption_path = os.path.splitext(final_path)[0] + ".txt"
                with open(caption_path, "w") as capf:
                    capf.write(f"{character_name} {full_caption}")

                composite_count += 1
                logger.info(f"[composite] {final_filename} => {full_caption}")

                if composite_count >= num_images_needed:
                    break

            bg_cycle += 1

        logger.info(f"[composite] Successfully generated {composite_count} images for {character_name}")


    def _generate_training_config(self, config_path: str, job_name: str, dataset_folder: str, base_model: str, gpu_id: int):
        output_path = f"/home/ubuntu/additional_storage/ai-toolkit/output"
        os.makedirs(output_path, exist_ok=True)

        template = f"""job: extension
config:
  name: "{job_name}"
  process:
    - type: 'sd_trainer'
      training_folder: "{output_path}"
      device: cuda:{gpu_id if gpu_id is not None else 0}
      network:
        type: "lora"
        linear: 16
        linear_alpha: 16
      save:
        dtype: float16
        save_every: 100
        max_step_saves_to_keep: 4
        push_to_hub: false
      datasets:
        - folder_path: "{dataset_folder}"
          caption_ext: "txt"
          caption_dropout_rate: 0.1
          shuffle_tokens: true
          cache_latents_to_disk: true
          resolution: [512, 768, 1024]
      train:
        batch_size: 1
        steps: 1000
        gradient_accumulation_steps: 1
        train_unet: true
        gradient_checkpointing: true
        noise_scheduler: "flowmatch"
        optimizer: "adamw8bit"
        lr: 0.0001
        ema_config:
          use_ema: true
          ema_decay: 0.99
        dtype: bf16
      model:
        name_or_path: "{base_model}"
        assistant_lora_path: "ostris/FLUX.1-schnell-training-adapter"
        is_flux: true
        quantize: true
      sample:
        sampler: "flowmatch"
        sample_every: 100
        width: 1024
        height: 768
        prompts:
          - "{job_name.split('_')[0]} is happy in cyberpunk style city"
          - "{job_name.split('_')[0]} is holding a magical staff in a fantasy forest"
          - "{job_name.split('_')[0]} riding a futuristic hoverboard through a neon cityscape at night"
          - "{job_name.split('_')[0]} sitting by a campfire"
        seed: 42
        walk_seed: true
        guidance_scale: 0.75
        sample_steps: 10
"""
        os.makedirs(os.path.dirname(config_path), exist_ok=True)
        with open(config_path, "w") as f:
            f.write(template)
        return config_path

    def get_logs(self, task_id: str) -> str:
        logs_list = self.logs.get(task_id, [])
        last_idx = self.last_read_index.get(task_id, 0)
        
        if last_idx >= len(logs_list):
            return ""
            
        # 새로운 로그만 반환
        new_logs = logs_list[last_idx:]
        self.last_read_index[task_id] = len(logs_list)
        
        return "".join(new_logs)


    def _setup_generate_image(self, character_name: str, gpu_id: int):
        """Generate and run the image generation interface"""
        try:
            # Deactivate current environment
            deactivate_cmd = "deactivate"
            subprocess.run(deactivate_cmd, shell=True)

            # Create output directory
            output_dir = f"/home/ubuntu/additional_storage/ai-toolkit/output/{character_name}_flux_lora_v1"
            os.makedirs(output_dir, exist_ok=True)

            # Generate the generate_image.py script - Always use GPU 7
            script_content = self._generate_image_script_content(character_name, 7)  # Always use GPU 7
            script_path = os.path.join(output_dir, "generate_image.py")
            
            with open(script_path, "w") as f:
                f.write(script_content)

            # Activate the correct environment and run the script
            commands = [
                "cd /home/ubuntu/additional_storage/ai-toolkit",
                "source venv/bin/activate",
                f"cd {output_dir}",
                "python generate_image.py"
            ]
            
            cmd = " && ".join(commands)
            process = subprocess.Popen(
                cmd,
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True
            )

            # Monitor the output for the server URL
            server_url = None
            for line in process.stdout:
                if "Running on local URL:" in line:
                    port_match = re.search(r":(\d+)", line)
                    if port_match:
                        port = port_match.group(1)
                        server_url = f"http://211.175.242.13:{port}"
                        logger.info(f"Image generation interface available at: {server_url}")
                        return server_url

        except Exception as e:
            logger.error(f"Error setting up generate_image.py: {str(e)}")
            raise

    def _generate_image_script_content(self, character_name: str, gpu_id: int):
        """Generate the content for generate_image.py"""
        return f'''import torch
from diffusers import FluxPipeline
from PIL import Image
import uuid
import os
import gradio as gr

# Device setup
device = torch.device('cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu')

# Load base model
base_model_path = "black-forest-labs/FLUX.1-schnell"
pipeline = FluxPipeline.from_pretrained(
    base_model_path,
    torch_dtype=torch.float16,
)

# Load LoRA weights
lora_weights_path = "./{character_name}_flux_lora_v1.safetensors"
pipeline.load_lora_weights(lora_weights_path)
pipeline.to(device)

# Aspect ratio to dimensions mapping
aspect_ratio_dimensions = {{
    'square': (768, 768),
    'portrait': (768, 1024),
    'standard': (1024, 768),
    'widescreen': (1024, 576)
}}

def generate_image(prompt, aspect_ratio, seed):
    try:
        height, width = aspect_ratio_dimensions[aspect_ratio]
        generator = torch.Generator(device=device).manual_seed(seed)
        
        with torch.no_grad():
            output = pipeline(
                prompt,
                num_inference_steps=15,
                guidance_scale=8.9,
                generator=generator,
                height=height,
                width=width,
            )
            
        output_dir = "generated_images"
        os.makedirs(output_dir, exist_ok=True)
        guid = uuid.uuid4()
        file_name = f'{{guid}}.png'
        file_path = os.path.join(output_dir, file_name)
        output.images[0].save(file_path)
        
        return output.images[0], f"Image saved at: {{file_path}}"
    except Exception as e:
        return None, f"Error: {{str(e)}}"

# Gradio interface
with gr.Blocks() as demo:
    gr.Markdown(f"# Filter of {character_name} image generator on playarts")
    
    with gr.Row():
        prompt_input = gr.Textbox(label="Prompt", placeholder="Enter your prompt here")
        aspect_ratio_input = gr.Radio(
            choices=['square', 'portrait', 'standard', 'widescreen'],
            value='square',
            label="Aspect Ratio"
        )
        seed_input = gr.Number(value=234, label="Seed", precision=0)
    
    generate_button = gr.Button("Generate Image")
    
    with gr.Row():
        image_output = gr.Image(label="Generated Image")
        status_output = gr.Textbox(label="Status", interactive=False)
    
    generate_button.click(
        generate_image,
        inputs=[prompt_input, aspect_ratio_input, seed_input],
        outputs=[image_output, status_output]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
'''